"""
ìˆœì°¨ ì¬ë²ˆì—­ ìŠ¤í¬ë¦½íŠ¸ â€” ë²ˆì—­ ì‹¤íŒ¨í•œ ê¸°ì‚¬ë§Œ Geminië¡œ ì¬ì²˜ë¦¬
ë³‘ë ¬ ì‹¤í–‰ ê¸ˆì§€, ê¸°ì‚¬ë‹¹ 10ì´ˆ ëŒ€ê¸°ë¡œ quota íšŒí”¼
"""
import json, time, os
import google.generativeai as genai
from dotenv import load_dotenv

load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-2.5-flash")

FAIL_MARKERS = ["ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘", "ë‚´ìš© ì—†ìŒ", "Summarization", "ì˜¤ë¥˜", ""]

def needs_translation(article):
    summary = article.get("summary_kr", "")
    title = article.get("title_kr", "")
    # ì›ë¬¸ ì œëª©ê³¼ ê°™ê±°ë‚˜ ì—ëŸ¬ ë©”ì‹œì§€ë©´ ì¬ë²ˆì—­ í•„ìš”
    return (
        not summary or
        any(m in summary for m in FAIL_MARKERS) or
        title == article.get("original_title", "")
    )

def translate(text, title):
    if not text or len(text) < 50:
        return None
    truncated = text[:3000]
    prompt = f"""
You are the editor of "Collective Monologue", a Korean-language magazine covering American theater and film.

Article title: '{title}'

Produce a rich Korean editorial covering:
1. Core news summary
2. Background on mentioned actors, productions, theaters, awards
3. Brief editor's perspective for Korean readers

Output ONLY a JSON object:
{{
    "title_kr": "ë§¤ë ¥ì ì¸ í•œêµ­ì–´ ì œëª©",
    "summary_kr": "1-2ë¬¸ì¥ í•µì‹¬ ìš”ì•½ (í•œêµ­ì–´, í´ë¦­í•˜ê³  ì‹¶ê²Œ)",
    "content_kr": "í’ë¶€í•œ ê¸°ì‚¬ ë³¸ë¬¸ (í•œêµ­ì–´, ì—¬ëŸ¬ ë¬¸ë‹¨, ë§ˆì§€ë§‰ì— í¸ì§‘ì ì£¼ í¬í•¨)",
    "reddit_reaction_kr": "",
    "keywords": ["keyword1", "keyword2", "keyword3"]
}}

Article:
{truncated}
"""
    for attempt in range(5):
        try:
            resp = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
            return json.loads(resp.text)
        except Exception as e:
            if "429" in str(e) or "quota" in str(e).lower():
                wait = 30 * (attempt + 1)
                print(f"  â³ Quota exceeded â€” {wait}ì´ˆ ëŒ€ê¸° (ì‹œë„ {attempt+1}/5)")
                time.sleep(wait)
            else:
                print(f"  âŒ API ì˜¤ë¥˜: {e}")
                return None
    return None

# articles.json ë¡œë“œ
with open("data/articles.json", encoding="utf-8") as f:
    articles = json.load(f)

patched = 0
for i, article in enumerate(articles):
    if not needs_translation(article):
        print(f"[{i}] âœ… OK: {article.get('title_kr','')[:40]}")
        continue

    print(f"\n[{i}] ğŸ”„ ì¬ë²ˆì—­ í•„ìš”: {article.get('original_title','')[:50]}")

    # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸° (trafilatura ì‚¬ìš©)
    import trafilatura
    import requests
    link = article.get("link", "")
    body = ""
    if link:
        try:
            r = requests.get(link, timeout=8, headers={"User-Agent": "Mozilla/5.0"})
            body = trafilatura.extract(r.text) or ""
        except Exception as e:
            print(f"  âš ï¸ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    result = translate(body or article.get("original_title",""), article.get("original_title",""))
    if result:
        for key in ["title_kr", "summary_kr", "content_kr", "reddit_reaction_kr", "keywords"]:
            if key in result:
                article[key] = result[key]
        articles[i] = article
        patched += 1
        print(f"  âœ… ë²ˆì—­ ì™„ë£Œ: {result.get('title_kr','')[:40]}")
    else:
        print(f"  âŒ ë²ˆì—­ ì‹¤íŒ¨ â€” ê±´ë„ˆëœ€")

    # ë§¤ ê¸°ì‚¬ë§ˆë‹¤ ì €ì¥ (ì¤‘ê°„ì— ëŠê²¨ë„ ì•ˆì „)
    with open("data/articles.json", "w", encoding="utf-8") as f:
        json.dump(articles, f, ensure_ascii=False, indent=4)

    print(f"  ğŸ’¾ ì €ì¥ ì™„ë£Œ. 10ì´ˆ ëŒ€ê¸°...")
    time.sleep(10)

print(f"\nâœ… ì¬ë²ˆì—­ ì™„ë£Œ: {patched}ê°œ ê¸°ì‚¬")
